data.py - read multiple files and seperate both languages and make some cleaning like removing leading and ending whitespace and removed unwanted symbols and finally
            create two text files of english and malayalam. Also a csv file of parallel corpus has been created

tokenizer_builder.py - build a tokenizer from old one : using t5 small transformer model tokenizer, we build a tokenizer for both english and malayalam
token_test.py - for testing tokenization 